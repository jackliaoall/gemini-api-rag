"""
YouTube channel scraper using Apify API.
Extracts video titles and subtitles/transcripts from a YouTube channel.
"""

import os
from typing import List, Dict, Optional
from apify_client import ApifyClient


class YouTubeScraper:
    """Handles scraping YouTube channel videos using Apify."""

    def __init__(self, api_token: str):
        """
        Initialize the YouTube scraper.

        Args:
            api_token: Apify API token
        """
        self.client = ApifyClient(api_token)

    def scrape_channel(
        self,
        channel_url: str,
        max_videos: int = 10
    ) -> List[Dict[str, str]]:
        """
        Scrape videos from a YouTube channel.

        Args:
            channel_url: URL of the YouTube channel
            max_videos: Maximum number of videos to scrape (from newest)

        Returns:
            List of dictionaries containing video data (title, url, transcript)
        """
        print(f"\nðŸ” Scraping channel: {channel_url}")
        print(f"ðŸ“Š Fetching up to {max_videos} videos...")

        # Configure the Apify actor run
        run_input = {
            "startUrls": [{"url": channel_url}],
            "maxResults": max_videos,
            "searchType": "channel",
            "downloadSubtitles": True,  # Download subtitles
            "subtitlesLanguage": "en",  # English subtitles
            "preferAutoGeneratedSubtitles": False,  # Prefer manual over auto-generated
        }

        # Run the actor and wait for it to finish
        print("â³ Running Apify scraper...")
        run = self.client.actor("streamers/youtube-scraper").call(run_input=run_input)

        # Fetch results from the dataset
        videos = []
        print("ðŸ“¥ Fetching results...")

        for item in self.client.dataset(run["defaultDatasetId"]).iterate_items():
            # Debug: Print available keys to understand data structure
            if not videos:  # Only print for first video
                print(f"\nðŸ” Debug - Available keys in response: {list(item.keys())}")
                if 'subtitles' in item:
                    print(f"ðŸ” Debug - Subtitles type: {type(item['subtitles'])}")
                    print(f"ðŸ” Debug - Subtitles sample: {str(item['subtitles'])[:200]}")

            video_data = {
                "title": item.get("title", "Untitled"),
                "url": item.get("url", ""),
                "video_id": item.get("id", ""),
                "transcript": self._extract_transcript(item),
                "description": item.get("description", ""),
                "duration": item.get("duration", ""),
                "views": item.get("viewCount", 0),
            }

            # Only add videos that have transcripts
            if video_data["transcript"]:
                videos.append(video_data)
                print(f"  âœ“ {video_data['title'][:60]}...")
            else:
                print(f"  âŠ— {video_data['title'][:60]}... (no transcript)")

        print(f"\nâœ… Successfully scraped {len(videos)} videos with transcripts")
        return videos

    def _extract_transcript(self, item: Dict) -> str:
        """
        Extract transcript/subtitles from video item.

        Args:
            item: Video data item from Apify

        Returns:
            Transcript text or empty string if not available
        """
        # Try multiple possible field names for subtitles
        possible_fields = ["subtitles", "subtitle", "subtitlesText", "text", "transcript"]

        for field in possible_fields:
            data = item.get(field)

            if not data:
                continue

            # Handle string data (could be plain text or SRT format)
            if isinstance(data, str):
                # If it's SRT format, parse it
                if self._is_srt_format(data):
                    return self._parse_srt(data)
                return data.strip()

            # Handle list/array data
            if isinstance(data, list):
                transcript_parts = []
                for subtitle in data:
                    if isinstance(subtitle, dict):
                        # Try different text fields
                        text = subtitle.get("text") or subtitle.get("content") or subtitle.get("line")
                        if text:
                            transcript_parts.append(text)
                    elif isinstance(subtitle, str):
                        transcript_parts.append(subtitle)

                if transcript_parts:
                    return " ".join(transcript_parts).strip()

        return ""

    def _is_srt_format(self, text: str) -> bool:
        """Check if text is in SRT subtitle format."""
        # SRT format has lines like: "1\n00:00:00,000 --> 00:00:05,000\nText"
        return "-->" in text and "\n" in text

    def _parse_srt(self, srt_text: str) -> str:
        """Parse SRT format and extract just the text."""
        lines = srt_text.split('\n')
        transcript_parts = []

        for i, line in enumerate(lines):
            # Skip subtitle numbers and timestamps
            if line.strip() and not line.strip().isdigit() and "-->" not in line:
                transcript_parts.append(line.strip())

        return " ".join(transcript_parts)


def test_scraper():
    """Test function for the YouTube scraper."""
    api_token = os.getenv("APIFY_API_TOKEN")

    if not api_token:
        print("Error: APIFY_API_TOKEN not set")
        return

    scraper = YouTubeScraper(api_token)

    # Test with a popular channel
    channel_url = "https://www.youtube.com/@mkbhd"
    videos = scraper.scrape_channel(channel_url, max_videos=3)

    print(f"\nFound {len(videos)} videos:")
    for video in videos:
        print(f"\nTitle: {video['title']}")
        print(f"URL: {video['url']}")
        print(f"Transcript length: {len(video['transcript'])} characters")


if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    test_scraper()
